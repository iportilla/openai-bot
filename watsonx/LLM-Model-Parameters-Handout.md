# LLM Model Parameters — Quick Reference Handout

## Temperature (Creativity)
Controls how predictable or creative the model is.
- Low (0.0–0.4): Factual, precise
- Medium (0.5–0.9): Balanced, conversational
- High (1.0+): Creative, varied

## Max Tokens
Controls response length. Increase if responses are cut off.

## Top-P (Nucleus Sampling)
Controls how many possible next-word choices are considered.

## Frequency Penalty
Reduces repeated phrases.

## Presence Penalty
Encourages introducing new ideas or topics.
